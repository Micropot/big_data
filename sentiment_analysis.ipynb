{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arthurlamard/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, GRU, Embedding\n",
    "from keras.layers import Activation, Bidirectional, GlobalMaxPool1D, GlobalMaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from keras.initializers import Constant\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from keras.utils import pad_sequences\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(text):\n",
    "    text=re.sub(r'https?://www\\.\\S+\\.com','',text)\n",
    "    text=re.sub(r'[^A-Za-z|\\s]','',text)\n",
    "    text=re.sub(r'\\*+','swear',text) #捕捉脏话 that are **** out\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # 表情符号\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # 符号和象形文字\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # 交通和地图符号\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # 标志 (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "# 最后，我们希望能够删除重复的字符（例如，因此我们有 \"way \"而不是 \"waaaayyyyy\"）。\n",
    "def remove_multiplechars(text):\n",
    "    text = re.sub(r'(.)\\1{3,}',r'\\1', text)\n",
    "    return text\n",
    "\n",
    "#为方便起见，我们将这四个函数合并为一个清理函数。\n",
    "def clean(df):\n",
    "    for col in ['text']:#,'selected_text']:\n",
    "        df[col]=df[col].astype(str).apply(lambda x:basic_cleaning(x))\n",
    "        df[col]=df[col].astype(str).apply(lambda x:remove_emoji(x))\n",
    "        df[col]=df[col].astype(str).apply(lambda x:remove_html(x))\n",
    "        df[col]=df[col].astype(str).apply(lambda x:remove_multiplechars(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
